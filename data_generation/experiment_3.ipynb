{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from data_generation import Three_body_2D_Rick\n",
    "from data_generation import tbp_util\n",
    "from data_generation.tbp_energy_calculations import visualize_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Experiment 3\n",
    "### NOTE: We do not have an overfitting model (yet) so regularizer sweep is not useful (actually we did but didn't notice in time)\n",
    "\n",
    "Retrain best models on all data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "experiment_id = \"Experiment_2\"\n",
    "config_name = \"breen-et-al-00001\"\n",
    "tbp_util.use_config(config_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# allow autoreloading of imported modules whenever running a cell\n",
    "# if not included, a kernel restart is needed whenever one of the imports is modified\n",
    "# (Needs experimenting / import statements to work)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# todo read from config file\n",
    "# also see tbp_util.py\n",
    "G = 1.0\n",
    "M = np.array([1.0, 1.0, 1.0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Choose example trajectory from the data set to visualize."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "example_dataset = \"325\"\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "visualize_dataset(*tbp_util.load_dataset(example_dataset), G, M)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x, y, vx, vy = tbp_util.load_dataset(example_dataset)\n",
    "x[0, :]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y[0, :]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# deltas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_deltas(x, y, vx, vy, delta=1, scaling_factor=1):\n",
    "    dx = (x[:-delta] - x[delta:]) * scaling_factor\n",
    "    dy = (y[:-delta] - y[delta:]) * scaling_factor\n",
    "    dvx = (vx[:-delta] - vx[delta:]) * scaling_factor\n",
    "    dvy = (vy[:-delta] - vy[delta:]) * scaling_factor\n",
    "    return dx, dy, dvx, dvy\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "deltas = get_deltas(x, y, vx, vy, 1, 100000)\n",
    "plt.figure()\n",
    "plt.boxplot(deltas[0], showfliers=False)\n",
    "plt.legend((\"x1 delta\",\"x2 delta\",\"x3 delta\"))\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.boxplot(deltas[2], showfliers=False)\n",
    "plt.legend((\"vx1 delta\",\"vx2 delta\",\"vx3 delta\"))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "keras.backend.set_floatx('float64')\n",
    "keras.backend.floatx()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load training data\n",
    "\n",
    "Load training data.\n",
    "A trajectory has t timesteps. For each time step it has 12 variables:\n",
    "- x, y, vx, vy for each of the 3 bodies\n",
    "\n",
    "The network is trained to predict 10 time steps into the future."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_datasets = 102\n",
    "prediction_offset = 10\n",
    "scaling_factor = 10000\n",
    "\n",
    "predict_deltas = True\n",
    "\n",
    "x_train = np.ndarray((0, 12), dtype=np.float64)\n",
    "y_train = np.ndarray((0, 12), dtype=np.float64)\n",
    "for dataset, x, y, vx, vy in tbp_util.load_datasets(limit=max_datasets):\n",
    "\n",
    "    input_data = np.column_stack((x, y, vx, vy))\n",
    "    input_data = input_data[:-prediction_offset:10, :]\n",
    "\n",
    "    deltas = get_deltas(x, y, vx, vy, delta=prediction_offset, scaling_factor=scaling_factor)\n",
    "    output_data = np.column_stack(deltas)[::10, :]\n",
    "\n",
    "    x_train = np.concatenate((x_train, input_data))\n",
    "    y_train = np.concatenate((y_train, output_data))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "first training example **[ x1, x2, x3, y1, y2, y3, vx1, vx2, vx3, vy1, vy2, vy3 ]**\n",
    "first testing  example **[ x1', x2', x3', y1', y2', y3', vx1', vx2', vx3', vy1', vy2', vy3' ]**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train[0,]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_train[0,]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Initialize model\n",
    "\n",
    "The model consists of 10 layers with 128 neurons. Initial testing has shown this model to be able to over-fit.\n",
    "The layers use a ReLU activation function and the 12 output neurons a linear function.\n",
    "\n",
    "The model has be trained on batches of size 256. 10% of the data set is set aside for validation.\n",
    "\n",
    "This set-up was used to do a preliminary search for network architecture:\n",
    "- learning rate\n",
    "- n layers, neurons, batch size, loss function\n",
    "\n",
    "# Fit model\n",
    "After every epoch, the model is automatically backed-up, so you can interrupt the kernel and go to validation steps during training if you're curious! Then just re-run the model.fit() step to continue training (might need some testing, lost the loss curve before)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 256\n",
    "validation_split = 0.1\n",
    "steps_per_epoch = round((x_train.shape[0] * (1 - validation_split)) / batch_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(128, activation=keras.activations.relu, input_shape=[12]),\n",
    "    keras.layers.Dense(128, activation=keras.activations.relu),\n",
    "    keras.layers.Dense(128, activation=keras.activations.relu),\n",
    "    keras.layers.Dense(128, activation=keras.activations.relu),\n",
    "    keras.layers.Dense(128, activation=keras.activations.relu),\n",
    "    keras.layers.Dense(128, activation=keras.activations.relu),\n",
    "    keras.layers.Dense(128, activation=keras.activations.relu),\n",
    "    keras.layers.Dense(128, activation=keras.activations.relu),\n",
    "    keras.layers.Dense(128, activation=keras.activations.relu),\n",
    "    keras.layers.Dense(128, activation=keras.activations.relu),\n",
    "    keras.layers.Dense(12, activation=keras.activations.linear)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='mae',\n",
    "    metrics=['mae', 'mse']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist_callback = keras.callbacks.History()\n",
    "callbacks = [\n",
    "    hist_callback,\n",
    "    keras.callbacks.BackupAndRestore(backup_dir=\"model_backup\")\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=validation_split,\n",
    "    callbacks=callbacks\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save model for later\n",
    "\n",
    "And plot of the loss as the epochs progress."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "model_id = f'{experiment_id}-{config_name}'\n",
    "model_path = f'./models/{experiment_id}/{config_name}'\n",
    "os.makedirs(model_path, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "for x in [\"h5\"]:\n",
    "    model.save(f\"{model_path}/{model_id}_model.{x}\", save_format=x)\n",
    "for x in [\"h5\", \"tf\"]:\n",
    "    model.save_weights(f\"{model_path}/{model_id}_weights.{x}\", save_format=x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.load_weights(f\"{model_path}/{model_id}_weights.h5\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(f\"Loss graph for {experiment_id}\")\n",
    "plt.plot(hist_callback.history['loss'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Quick validation set-up\n",
    "\n",
    "Choose a trajectory from the dataset.\n",
    "Visualize trajectory\n",
    "use model to predict the same trajectory ( but in fewer steps! )\n",
    "compare the 2 trajectory plots\n",
    "# todo compare the loss or something\n",
    "# todo save results of validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_to_predict = '72'\n",
    "dataset_to_predict = '18'\n",
    "x, y, vx, vy = tbp_util.load_dataset(dataset_to_predict)\n",
    "print(x.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "length_to_predict = int(x.shape[0] / prediction_offset)\n",
    "print(f\"The original trajectory is T={x.shape[0]} time steps long, so we have to predict T/prediction_offset={x.shape[0]}/{prediction_offset}={length_to_predict} steps because we predict {prediction_offset} steps into the future.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "limit = length_to_predict\n",
    "y_pred = np.zeros((limit, 12), dtype=np.float64)\n",
    "y_pred[0,] = np.concatenate((x[0,], y[0,], vx[0,], vy[0,]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(limit - 1):\n",
    "    prediction = model(y_pred[i,].reshape(1, 12), training=False).numpy()\n",
    "    if predict_deltas:\n",
    "        prediction /= scaling_factor\n",
    "        prediction = y_pred[i,].reshape(1, 12) - prediction\n",
    "\n",
    "    # stop early when the system gets out of bounds\n",
    "    if np.min(prediction[0, :6]) < -3 or np.max(prediction[0, :6]) > 3 or np.min(prediction) < -20 or np.max(\n",
    "            prediction) > 20:\n",
    "        print(f\"Stop predicting at t={i * prediction_offset} ({i} steps) after encountering {prediction}\")\n",
    "        break\n",
    "\n",
    "    y_pred[i + 1,] = prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Real trajectory\n",
    "visualize_dataset(*tbp_util.load_dataset(dataset_to_predict), G, M, down_sample_factor=prediction_offset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Predicted trajectory\n",
    "pred_x, pred_y, pred_vx, pred_vy = np.hsplit(y_pred, 4)\n",
    "visualize_dataset(pred_x, pred_y, pred_vx, pred_vy, G, M, down_sample_factor=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import Three_body_2D_Rick\n",
    "\n",
    "# Comparison plot\n",
    "true_x, true_y, _, _ = tbp_util.load_dataset(dataset_to_predict)\n",
    "Three_body_2D_Rick.compare_plot(true_x, true_y, pred_x, pred_y, savefig=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
